{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Shehzad's Final Year Project",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1432479,
          "sourceType": "datasetVersion",
          "datasetId": 839140
        },
        {
          "sourceId": 1659908,
          "sourceType": "datasetVersion",
          "datasetId": 982666
        },
        {
          "sourceId": 2020950,
          "sourceType": "datasetVersion",
          "datasetId": 1209563
        },
        {
          "sourceId": 5618375,
          "sourceType": "datasetVersion",
          "datasetId": 3230595
        }
      ],
      "dockerImageVersionId": 30408,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArooshAhmad-Data/Machine-Learning-Codes/blob/master/Shehzad's_Final_Year_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'chest-ctscan-images:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F839140%2F1432479%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240310%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240310T125112Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D774d2e2c19d1dc656639095eea1ddbbf77e2c222b653999d010f88788257cac5ca73b8c0007559cc2705d2f6983357f3425a21ee134bd14f44e44797ddaba9d3483f43d27c350ddc1dde40f0a4bab0dc100637a701947b578e04856c1c7726ddec062a0fbfc03c3fcca7d645ad89110578ec6afb17d9c90d50b2e397b6c8f02cf8cb6dc8fe569d8bde9b5cb0060320673c2bbcd83e0bf36dbaaea1fb51246b5eb71cfbdbb1e82b55f5ca9cb07eb6c0528a571c3f4dacf1c76c926ab852d7f7e09e9f84edcc51c5323ecef5a1ff4da9006f18a12a3284eb36804231c48d629efedeb99182ed314f9b347c4462b3c62330994f7158b856df14d0392b9f98c3e35d,luna16:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F982666%2F1659908%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240310%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240310T125112Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3771178914905f9cbc22718a36d550f0111c226692c8e88ababc38d27f02903ef2ae3b5830c9b84baf709389d1299be8e0c263000a266d3666d6317da8e5cfb74b931801fc8b82624a991fe3575c5efb8316cbe1b26d72faf72ba3a19dfef66b80357c222b5387d8ea03860fd1e2fda0d8daf214eb010e5c4c3e271e773b46a4d6b61459ae20cff42a5ecdb90efa7f308c80d0a9d07612ba31697950dd6e66495386c9598dd09f5f3ff916843c4fef2138bc77651b29d2564120f813b3a08f84435d7d7809aaf1e76d4b66e758e9d3e7597d3b868730a3e4a5497581d2f8a0a72ffcd42c8145d2feaf295b8f06f3f9a46ab484104c1f89ef16bc58bce0115c0d,luna-lung-cancer-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1209563%2F2020950%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240310%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240310T125112Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D272cb5dd0fbe1806cc9c2e3a6cf59de11e189127ed80abddbfe87432e32095f0221a8cb23e6846ff5929d4dddd3e04b4509ffd676580fdceb56a86fb237fd92df6f1fa477485058208d20dd78eee73318a911efd5e8b2f75795c2a9681172ad30c1f38c94a54d3508c221be3f24ed5d5fc095c9e2cfbdfc01a7d9ffca8a1b92a81d69fc10381e3bc8d73a6dbef29c852d69cee2cb1b79581303b4fc9929ec78aaf222cf3353db0255216aa7354769756303f0f39b24b5d177c50834bb34ca6da726bb4e860ff7fe4704168bb2e1a1e5e455932068080da6e1cade34b68138882b158e5a35b4f8ab7b92d1cb7de3059b24afb02b64682530f94bc8506e2845149'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "f0WVbDIvaulM"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a necessary library that, i installed here, which was causing issue in local environment\n",
        "# so want to install it whenever run this notebook, even if it's already installed.\n",
        "!pip install SimpleITK"
      ],
      "metadata": {
        "id": "oI3Q5Wh6MAH8",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:25.99549Z",
          "iopub.execute_input": "2024-03-10T12:28:25.996636Z",
          "iopub.status.idle": "2024-03-10T12:28:37.747182Z",
          "shell.execute_reply.started": "2024-03-10T12:28:25.99658Z",
          "shell.execute_reply": "2024-03-10T12:28:37.746026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import SimpleITK as stk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage import measure"
      ],
      "metadata": {
        "id": "NASu--FXNV7I",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:37.750049Z",
          "iopub.execute_input": "2024-03-10T12:28:37.750946Z",
          "iopub.status.idle": "2024-03-10T12:28:37.757387Z",
          "shell.execute_reply.started": "2024-03-10T12:28:37.750898Z",
          "shell.execute_reply": "2024-03-10T12:28:37.756274Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/kaggle/input/luna16/\"\n",
        "target_root = \"//kaggle/input/luna16/processed/\""
      ],
      "metadata": {
        "id": "zKAb5VRtNaAH",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:37.758786Z",
          "iopub.execute_input": "2024-03-10T12:28:37.759079Z",
          "iopub.status.idle": "2024-03-10T12:28:37.770162Z",
          "shell.execute_reply.started": "2024-03-10T12:28:37.75905Z",
          "shell.execute_reply": "2024-03-10T12:28:37.769109Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "# Base path for the LUNA16 dataset\n",
        "base_path = '/kaggle/input/luna16/'\n",
        "\n",
        "# Loop through the subsets you want to read, adjust the range as needed\n",
        "for subset in range(0,4):  # This will loop through subset0 and subset1\n",
        "    # Update the path for glob to match the directory structure\n",
        "    file_list = glob(f\"{base_path}/subset{subset}/subset{subset}/*.mhd\")\n",
        "\n",
        "    # Print out the count of files for each subset\n",
        "    print(f\"Files in subset{subset} Count:\", len(file_list))\n",
        "\n",
        "# Read the annotations file if it's located directly under the luna16 folder\n",
        "annotations_df = pd.read_csv(f\"{base_path}/annotations.csv\")\n",
        "print(\"Annotations DF Count:\", len(annotations_df))\n",
        "annotations_df.head()\n"
      ],
      "metadata": {
        "id": "2BHgANqANjEE",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:37.773238Z",
          "iopub.execute_input": "2024-03-10T12:28:37.773863Z",
          "iopub.status.idle": "2024-03-10T12:28:37.813042Z",
          "shell.execute_reply.started": "2024-03-10T12:28:37.773833Z",
          "shell.execute_reply": "2024-03-10T12:28:37.811977Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = annotations_df['diameter_mm'].values\n",
        "fig = plt.hist(d, bins=80)"
      ],
      "metadata": {
        "id": "cukw_lPzNtAG",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:37.814513Z",
          "iopub.execute_input": "2024-03-10T12:28:37.814925Z",
          "iopub.status.idle": "2024-03-10T12:28:38.172245Z",
          "shell.execute_reply.started": "2024-03-10T12:28:37.814882Z",
          "shell.execute_reply": "2024-03-10T12:28:38.171229Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filename(file_list, file):\n",
        "    for f in file_list:\n",
        "        if file in f:\n",
        "            return f"
      ],
      "metadata": {
        "id": "nQWuIPzgN6rK",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.173594Z",
          "iopub.execute_input": "2024-03-10T12:28:38.173966Z",
          "iopub.status.idle": "2024-03-10T12:28:38.179231Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.173925Z",
          "shell.execute_reply": "2024-03-10T12:28:38.178101Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_df[\"filename\"] = annotations_df[\"seriesuid\"].map(lambda file: get_filename(file_list, file))\n",
        "annotations_df = annotations_df.dropna()\n",
        "annotations_df = annotations_df[annotations_df['diameter_mm']>=3.9]     # Excluding nodules with diameter less than 3.9mm\n",
        "print(len(annotations_df))"
      ],
      "metadata": {
        "id": "LSYDuZxhN-jS",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.180712Z",
          "iopub.execute_input": "2024-03-10T12:28:38.181547Z",
          "iopub.status.idle": "2024-03-10T12:28:38.213119Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.181465Z",
          "shell.execute_reply": "2024-03-10T12:28:38.211979Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_df.head()"
      ],
      "metadata": {
        "id": "OIPIc5bLOAld",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.214546Z",
          "iopub.execute_input": "2024-03-10T12:28:38.214917Z",
          "iopub.status.idle": "2024-03-10T12:28:38.229657Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.214867Z",
          "shell.execute_reply": "2024-03-10T12:28:38.228613Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mhd(file):\n",
        "    mhdimage = stk.ReadImage(file)\n",
        "    ct_scan = stk.GetArrayFromImage(mhdimage)\n",
        "    origin = np.array(list(mhdimage.GetOrigin()))\n",
        "    space = np.array(list(mhdimage.GetSpacing()))\n",
        "    return ct_scan, origin, space"
      ],
      "metadata": {
        "id": "f-KEWJnNODDi",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.23096Z",
          "iopub.execute_input": "2024-03-10T12:28:38.231331Z",
          "iopub.status.idle": "2024-03-10T12:28:38.238066Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.231293Z",
          "shell.execute_reply": "2024-03-10T12:28:38.237172Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_mask(img, center, diam):\n",
        "    mask = np.zeros_like(img, dtype=np.uint8)\n",
        "    mask = cv2.circle(mask, (abs(int(center[0])),abs(int(center[1]))),int(abs(diam//2)), 255, -1)\n",
        "    return mask"
      ],
      "metadata": {
        "id": "8lt_OOkbOFLP",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.242097Z",
          "iopub.execute_input": "2024-03-10T12:28:38.242504Z",
          "iopub.status.idle": "2024-03-10T12:28:38.248812Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.24246Z",
          "shell.execute_reply": "2024-03-10T12:28:38.247836Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_df_new = pd.read_csv(\"/kaggle/input/luna-lung-cancer-dataset/annotations.csv\")\n",
        "annotations_df_new"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.250144Z",
          "iopub.execute_input": "2024-03-10T12:28:38.250481Z",
          "iopub.status.idle": "2024-03-10T12:28:38.274558Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.25042Z",
          "shell.execute_reply": "2024-03-10T12:28:38.273483Z"
        },
        "trusted": true,
        "id": "_3rzcTe3aulV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbour = 4"
      ],
      "metadata": {
        "id": "VdUFFrXAOHq6",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.275752Z",
          "iopub.execute_input": "2024-03-10T12:28:38.276041Z",
          "iopub.status.idle": "2024-03-10T12:28:38.280514Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.275998Z",
          "shell.execute_reply": "2024-03-10T12:28:38.279479Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_root = '/kaggle/working/'\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "# from your_module import load_mhd, make_mask  # Make sure to import your actual function\n",
        "from skimage import measure\n",
        "import cv2\n",
        "\n",
        "# Define your target root directory\n",
        "target_root = '/kaggle/working/'\n",
        "\n",
        "# CLAHE filter for enhancing the contrast of an image\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "# Define the directories for saving output\n",
        "nodule_mask_dir = os.path.join(target_root, \"nodule_mask/\")\n",
        "lungs_roi_dir = os.path.join(target_root, \"lungs_roi/\")\n",
        "\n",
        "# Create the directories if they do not exist\n",
        "os.makedirs(nodule_mask_dir, exist_ok=True)\n",
        "os.makedirs(lungs_roi_dir, exist_ok=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.28184Z",
          "iopub.execute_input": "2024-03-10T12:28:38.282197Z",
          "iopub.status.idle": "2024-03-10T12:28:38.291289Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.282159Z",
          "shell.execute_reply": "2024-03-10T12:28:38.290281Z"
        },
        "trusted": true,
        "id": "3yyVWplaaulW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))  # CLAHE(Contrast Limited Adaptive Histogram Equalization) filter for enhancing the contrast of an image\n",
        "# Import necessary library\n",
        "import os\n",
        "\n",
        "# Define the directories for saving output\n",
        "nodule_mask_dir = os.path.join(target_root, \"nodule_mask/\")\n",
        "lungs_roi_dir = os.path.join(target_root, \"lungs_roi/\")\n",
        "\n",
        "# Create the directories if they do not exist\n",
        "os.makedirs(nodule_mask_dir, exist_ok=True)\n",
        "os.makedirs(lungs_roi_dir, exist_ok=True)\n",
        "# Iterating over all the files in the subset\n",
        "for i,file in tqdm(enumerate(np.unique(annotations_df['filename'].values))):\n",
        "    annotations = annotations_df[annotations_df[\"filename\"]==file]\n",
        "    ct, origin, space = load_mhd(file)      # Loading the CT scan\n",
        "    num_z, height, width = ct.shape\n",
        "    ct_norm = cv2.normalize(ct, None, 0, 255, cv2.NORM_MINMAX)   # Normalizing the CT scan\n",
        "    for idx, row in annotations.iterrows():\n",
        "        node_x = int(row[\"coordX\"])     # X coordinate of the nodule\n",
        "        node_y = int(row[\"coordY\"])     # Y coordinate of the nodule\n",
        "        node_z = int(row[\"coordZ\"])     # Z coordinate of the nodule\n",
        "        diam = int(row[\"diameter_mm\"])  # Diameter of the nodule\n",
        "\n",
        "        center = np.array([node_x, node_y, node_z])   # nodule center (x,y,z)\n",
        "        v_center = np.rint((center-origin)/space)   # nodule center in voxel space (still x,y,z ordering)\n",
        "        v_diam = int(diam/space[0])+5       # Diameter of the nodule in voxel space\n",
        "\n",
        "        img_norm_neighbours = []\n",
        "        img_norm_improved_neighbours = []\n",
        "        mask_neighbours = []\n",
        "        img_norm = None\n",
        "        img_norm_improved = None\n",
        "        mask = None\n",
        "\n",
        "        if 18<v_diam<22:              # If nodule diameter is of medium size the take two neighbour slides into consideration\n",
        "            n_neighbour = 2\n",
        "\n",
        "        min_i = max(0,(int(v_center[2])-n_neighbour))\n",
        "        max_i = min((int(v_center[2])+n_neighbour),(num_z-1))\n",
        "        n = max_i-min_i\n",
        "\n",
        "        img_norm = ct_norm[int(v_center[2]),:,:]    # a slice of the CT scan containing the nodule\n",
        "        img_norm = cv2.resize(img_norm, (512,512))  # Resizing the CT scan to 512x512\n",
        "        img_norm_improved = clahe.apply(img_norm.astype(np.uint8))  # Applying CLAHE filter to the image\n",
        "        mask = make_mask(img_norm, v_center, v_diam)    # Creating a mask of the nodule\n",
        "\n",
        "        if v_diam>18:      # If the nodule is too big, we will also take neighboring slices\n",
        "            for i in range(min_i, max_i+1):\n",
        "                if i==int(v_center[2]):\n",
        "                    continue\n",
        "\n",
        "                im_n = ct_norm[i,:,:]\n",
        "                im_n = cv2.resize(im_n, (512,512))\n",
        "                im_n_improved = clahe.apply(im_n.astype(np.uint8))\n",
        "                dia = int(2*abs(v_center[2]-i))    # Decrease mask diameter because nodule diameter decrease as we move away from its center\n",
        "                msk = make_mask(im_n, v_center, v_diam-dia)\n",
        "                img_norm_neighbours.append(im_n)\n",
        "                img_norm_improved_neighbours.append(im_n_improved)\n",
        "                mask_neighbours.append(msk)\n",
        "            assert len(img_norm_neighbours)==len(img_norm_improved_neighbours)==len(mask_neighbours)==n\n",
        "\n",
        "        # Calculating the threshold value for extracting the nodule mask using binary thresholding\n",
        "        mask = cv2.bitwise_and(img_norm, img_norm, mask=cv2.dilate(mask,kernel=np.ones((5,5))))\n",
        "        pts = mask[mask>0]\n",
        "        kmeans2 = KMeans(n_clusters=2).fit(np.reshape(pts,(len(pts),1)))\n",
        "        centroids2 = sorted(kmeans2.cluster_centers_.flatten())\n",
        "        threshold2 = np.mean(centroids2)\n",
        "\n",
        "        _, mask = cv2.threshold(mask, threshold2, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "        if v_diam>18:\n",
        "            for i in range(n):\n",
        "                mask_neighbours[i] = cv2.bitwise_and(img_norm_neighbours[i], img_norm_neighbours[i], mask=cv2.dilate(mask_neighbours[i],kernel=np.ones((5,5))))\n",
        "                _, mask_neighbours[i] = cv2.threshold(mask_neighbours[i], threshold2, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "        # Calculating the threshold value to segment the lungs from CT scan slices using binary thresholding\n",
        "        centeral_area = img_norm[100:400, 100:400]\n",
        "        kmeans = KMeans(n_clusters=2).fit(np.reshape(centeral_area, [np.prod(centeral_area.shape), 1]))\n",
        "        centroids = sorted(kmeans.cluster_centers_.flatten())\n",
        "        threshold = np.mean(centroids)\n",
        "\n",
        "        # Steps to segment the lungs from CT scan slices\n",
        "        ret, lung_roi = cv2.threshold(img_norm, threshold, 255, cv2.THRESH_BINARY_INV)\n",
        "        lung_roi = cv2.erode(lung_roi, kernel=np.ones([4,4]))\n",
        "        lung_roi = cv2.dilate(lung_roi, kernel=np.ones([13,13]))\n",
        "        lung_roi = cv2.erode(lung_roi, kernel=np.ones([8,8]))\n",
        "\n",
        "        labels = measure.label(lung_roi)        # Labelling different regions in the image\n",
        "        regions = measure.regionprops(labels)   # Extracting the properties of the regions\n",
        "        good_labels = []\n",
        "        for prop in regions:        # Filtering the regions that are not too close to the edges\n",
        "            B = prop.bbox           # Regions that are too close to the edges are outside regions of lungs\n",
        "            if B[2]-B[0] < 475 and B[3]-B[1] < 475 and B[0] > 40 and B[2] < 472:\n",
        "                good_labels.append(prop.label)\n",
        "        lung_roi_mask = np.zeros_like(labels)\n",
        "        for N in good_labels:\n",
        "            lung_roi_mask = lung_roi_mask + np.where(labels == N, 1, 0)\n",
        "\n",
        "        # Steps to get proper segmentation of the lungs without noise and holes\n",
        "        contours, hirearchy = cv2.findContours(lung_roi_mask,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        external_contours = np.zeros(lung_roi_mask.shape)\n",
        "        for i in range(len(contours)):\n",
        "            if hirearchy[0][i][3] == -1:  #External Contours\n",
        "                area = cv2.contourArea(contours[i])\n",
        "                if area>518.0:\n",
        "                    cv2.drawContours(external_contours,contours,i,(1,1,1),-1)\n",
        "        external_contours = cv2.dilate(external_contours, kernel=np.ones([4,4]))\n",
        "\n",
        "        external_contours = cv2.bitwise_not(external_contours.astype(np.uint8))\n",
        "        external_contours = cv2.erode(external_contours, kernel=np.ones((7,7)))\n",
        "        external_contours = cv2.bitwise_not(external_contours)\n",
        "        external_contours = cv2.dilate(external_contours, kernel=np.ones((12,12)))\n",
        "        external_contours = cv2.erode(external_contours, kernel=np.ones((12,12)))\n",
        "\n",
        "        img_norm_improved = img_norm_improved.astype(np.uint8)\n",
        "        external_contours = external_contours.astype(np.uint8)      # Final segmentated lungs mask\n",
        "        extracted_lungs = cv2.bitwise_and(img_norm_improved, img_norm_improved, mask=external_contours)\n",
        "\n",
        "        mask = mask.astype(np.uint8)\n",
        "        np.save(os.path.join(\"/kaggle/working/\"+\"nodule_mask/\", f\"masks_{subset}_{i}_{idx}.npy\"), mask)\n",
        "        np.save(os.path.join(\"/kaggle/working/\"+\"lungs_roi/\", f\"lungs_{subset}_{i}_{idx}.npy\"), extracted_lungs)\n",
        "\n",
        "        extracted_lungs_neighbours = [None]*n\n",
        "\n",
        "        if v_diam>18:\n",
        "            for i in range(n):\n",
        "                img_norm_improved_neighbours[i] = img_norm_improved_neighbours[i].astype(np.uint8)\n",
        "                extracted_lungs_neighbours[i] = cv2.bitwise_and(img_norm_improved_neighbours[i], img_norm_improved_neighbours[i], mask=external_contours)\n",
        "                mask_neighbours[i] = mask_neighbours[i].astype(np.uint8)\n",
        "                np.save(os.path.join(\"/kaggle/working/\"+\"nodule_mask/\", f\"masks_{subset}_{i}_{idx}_{i}.npy\"), mask_neighbours[i])\n",
        "                np.save(os.path.join(\"/kaggle/working/\"+\"lungs_roi/\", f\"lungs_{subset}_{i}_{idx}_{i}.npy\"), extracted_lungs_neighbours[i])"
      ],
      "metadata": {
        "id": "XZvW3LSAOJbp",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:28:38.292701Z",
          "iopub.execute_input": "2024-03-10T12:28:38.293019Z",
          "iopub.status.idle": "2024-03-10T12:29:09.709669Z",
          "shell.execute_reply.started": "2024-03-10T12:28:38.292982Z",
          "shell.execute_reply": "2024-03-10T12:29:09.708577Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelisation"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:09.711402Z",
          "iopub.execute_input": "2024-03-10T12:29:09.711798Z",
          "iopub.status.idle": "2024-03-10T12:29:09.716387Z",
          "shell.execute_reply.started": "2024-03-10T12:29:09.711758Z",
          "shell.execute_reply": "2024-03-10T12:29:09.715359Z"
        },
        "trusted": true,
        "id": "8jFEXQToaulX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After preparing my data, segmenting the lung areas, and saving the nodule masks along with the lung regions of interest (ROI), the next step is to build and train a deep learning model for segmentation or classification (cancer detection) based on our objectives.\n",
        "\n",
        "Here is how to proceed with modeling, training, and evaluating my model:"
      ],
      "metadata": {
        "id": "nYDYavhOaulX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Data preparation."
      ],
      "metadata": {
        "id": "DGC16LK9aulZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Step 1: Load the images and masks.\n"
      ],
      "metadata": {
        "id": "IVb0AHsKaulZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lung-extracted images (lungs_roi) and nodule masks (nodule_mask) are stored in .npy files. Now, we need to load them and associate them with the corresponding labels."
      ],
      "metadata": {
        "id": "788HtC1taula"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing both lung region images (ROI - Region of Interest) and nodule masks for multiple cases helps you understand where nodules are located and potentially whether these nodules can be indicative of cancer.\n",
        "\n",
        "- The reason we use masks in this context is to specifically identify regions of interest (nodules) in lung images.\n",
        "- A mask indicates the exact location of the nodule in the image, which is crucial for cancer analysis and detection. Deep learning models can use these masks to learn how to distinguish potential nodules from the rest of the lung tissue."
      ],
      "metadata": {
        "id": "0pgzuV3laula"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Exemple de chemin vers une image et son masque\n",
        "image_path = '/kaggle/working/lungs_roi/lungs_3_11_736.npy'  # Mettez à jour avec votre chemin réel\n",
        "mask_path = '/kaggle/working/nodule_mask/masks_3_11_736.npy'  # Mettez à jour avec votre chemin réel\n",
        "\n",
        "# Chargement de l'image et du masque\n",
        "image = np.load(image_path)\n",
        "mask = np.load(mask_path)\n",
        "\n",
        "# Affichage de l'image\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title('Image de région pulmonaire')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.title('Masque de nodule')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:09.717992Z",
          "iopub.execute_input": "2024-03-10T12:29:09.718458Z",
          "iopub.status.idle": "2024-03-10T12:29:09.94573Z",
          "shell.execute_reply.started": "2024-03-10T12:29:09.718394Z",
          "shell.execute_reply": "2024-03-10T12:29:09.944676Z"
        },
        "trusted": true,
        "id": "yrBQGZIAaula"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This script loads and displays a specified number of images and masks.\n",
        "\n",
        "- Visualizing these images helps you understand how nodules are represented in the data and how the masks identify these nodules.\n",
        "- It is an essential step to check the quality of your preprocessing and to understand the data on which our model will be trained."
      ],
      "metadata": {
        "id": "zMPrRCJkaula"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Lung segmentation (extraction of ROIs) and nodule masks are two key steps to isolate relevant areas for analysis and reduce noise and distractions in the images, allowing the model to focus only on the important parts."
      ],
      "metadata": {
        "id": "CzAbm0Msaulb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "# Paths to the directories containing lung-extracted images and nodule masks\n",
        "lungs_roi_dir = \"/kaggle/working/lungs_roi/\"\n",
        "nodule_mask_dir = \"/kaggle/working/nodule_mask/\"\n",
        "\n",
        "# Obtention des chemins de fichiers\n",
        "lungs_images_paths = glob(lungs_roi_dir + \"*.npy\")\n",
        "nodule_masks_paths = glob(nodule_mask_dir + \"*.npy\")\n",
        "\n",
        "# Get file paths\n",
        "lungs_images_paths.sort()\n",
        "nodule_masks_paths.sort()\n",
        "\n",
        "# Ensure paths are sorted to match images with their masks\n",
        "n_images_to_show = 5  # ou len(lungs_images_paths) pour afficher toutes les images\n",
        "\n",
        "plt.figure(figsize=(10, 5 * n_images_to_show))\n",
        "\n",
        "for i in range(min(n_images_to_show, len(lungs_images_paths))):\n",
        "    # Define how many images you want to visualize\n",
        "    image = np.load(lungs_images_paths[i])\n",
        "    mask = np.load(nodule_masks_paths[i])\n",
        "\n",
        "    plt.subplot(n_images_to_show, 2, 2*i+1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Image {i+1}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(n_images_to_show, 2, 2*i+2)\n",
        "    plt.imshow(mask, cmap='gray')\n",
        "    plt.title(f'Mask {i+1}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:09.94705Z",
          "iopub.execute_input": "2024-03-10T12:29:09.947364Z",
          "iopub.status.idle": "2024-03-10T12:29:10.806457Z",
          "shell.execute_reply.started": "2024-03-10T12:29:09.947334Z",
          "shell.execute_reply": "2024-03-10T12:29:10.805389Z"
        },
        "trusted": true,
        "id": "KyyJU5yLaulb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Visualization of these images helps you understand how nodules are represented in the data and how the masks identify these nodules."
      ],
      "metadata": {
        "id": "Iv9bT3woaulb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Preparation of X and y\n",
        "\n",
        "- X: The loaded images (lungs_roi) serve as input data for our model.\n",
        "- y: The nodule masks, after processing, act as labels indicating the presence or absence of nodules.\n",
        "- Normalization: The images are normalized to have values between 0 and 1, which is a standard practice to enhance the training of deep learning models.\n",
        "- Creation of y labels: We have defined y in a binary manner, where 1 indicates the presence of a nodule, and 0 indicates its absence. The logic behind this creation depends on the presence of non-zero pixels in the image, signifying the presence of nodules."
      ],
      "metadata": {
        "id": "W74q9ALyaulb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# Paths to the directories containing lung-extracted images and nodule masks\n",
        "lungs_roi_dir = \"/kaggle/working/lungs_roi/\"\n",
        "nodule_mask_dir = \"/kaggle/working/nodule_mask/\"\n",
        "\n",
        "# Load images (X) and masks (y)\n",
        "lungs_images_paths = glob(lungs_roi_dir + \"*.npy\")\n",
        "nodule_masks_paths = glob(nodule_mask_dir + \"*.npy\")\n",
        "\n",
        "# Ensure paths are sorted so that each image matches its mask\n",
        "lungs_images_paths.sort()\n",
        "nodule_masks_paths.sort()\n",
        "\n",
        "X = np.array([np.load(path) for path in lungs_images_paths])\n",
        "y = np.array([np.load(path) for path in nodule_masks_paths])\n",
        "\n",
        "# Normalize the images\n",
        "X = X / 255.0\n",
        "\n",
        "# For labels, decide on the logic based on the presence or absence of a nodule:\n",
        "# Here, a simplified example where y is binary: 1 if a nodule is present, 0 otherwise.\n",
        "y = np.array([1 if np.any(mask) else 0 for mask in y])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:10.807928Z",
          "iopub.execute_input": "2024-03-10T12:29:10.808298Z",
          "iopub.status.idle": "2024-03-10T12:29:11.241318Z",
          "shell.execute_reply.started": "2024-03-10T12:29:10.808263Z",
          "shell.execute_reply": "2024-03-10T12:29:11.240066Z"
        },
        "trusted": true,
        "id": "kUzd9Ol0aulc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Splitting into training, validation, and test sets\n",
        "\n"
      ],
      "metadata": {
        "id": "cJBCyqIraulc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:11.242936Z",
          "iopub.execute_input": "2024-03-10T12:29:11.24333Z",
          "iopub.status.idle": "2024-03-10T12:29:11.499679Z",
          "shell.execute_reply.started": "2024-03-10T12:29:11.243288Z",
          "shell.execute_reply": "2024-03-10T12:29:11.498743Z"
        },
        "trusted": true,
        "id": "8srKeeNqaulc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# For images\n",
        "image_files = os.listdir('/kaggle/working/lungs_roi/')\n",
        "print(\"Number of images:\", len(image_files))\n",
        "\n",
        "# For masks\n",
        "mask_files = os.listdir('/kaggle/working/nodule_mask/')\n",
        "print(\"Number of masks:\", len(mask_files))\n",
        "\n",
        "# Check that each image has its corresponding mask\n",
        "assert len(image_files) == len(mask_files), \"The number of images and masks do not match.\"\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:11.501026Z",
          "iopub.execute_input": "2024-03-10T12:29:11.501756Z",
          "iopub.status.idle": "2024-03-10T12:29:11.510801Z",
          "shell.execute_reply.started": "2024-03-10T12:29:11.501711Z",
          "shell.execute_reply": "2024-03-10T12:29:11.509765Z"
        },
        "trusted": true,
        "id": "P9cyxGftaulc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation"
      ],
      "metadata": {
        "id": "jg4lrDt5auld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths to directories where your image and mask files are located\n",
        "images_dir = '/kaggle/working/lungs_roi/'\n",
        "masks_dir = '/kaggle/working/nodule_mask/'\n",
        "\n",
        "# List all files in the directories\n",
        "image_files = os.listdir(images_dir)\n",
        "mask_files = os.listdir(masks_dir)\n",
        "\n",
        "# Ensure that for each image, there is a corresponding mask\n",
        "for image_file in image_files:\n",
        "    # Remove the extension and any potential suffix to get the base identifier\n",
        "    base_id = image_file.split('.')[0].rsplit('_', 1)[0]\n",
        "    corresponding_mask = base_id + '_mask.npy'  # This is just an example, adjust according to your file names\n",
        "    if corresponding_mask not in mask_files:\n",
        "        print(f\"Corresponding mask not found for the image: {image_file}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:29:11.511942Z",
          "iopub.execute_input": "2024-03-10T12:29:11.512294Z",
          "iopub.status.idle": "2024-03-10T12:29:11.524643Z",
          "shell.execute_reply.started": "2024-03-10T12:29:11.512264Z",
          "shell.execute_reply": "2024-03-10T12:29:11.523541Z"
        },
        "trusted": true,
        "id": "W_4Pyrwcauld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Modelisation simple"
      ],
      "metadata": {
        "id": "xb7hHmOXauld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser un modèle simple de CNN (réseau de neurones convolutifs) pour la classification binaire des nodules (présence de cancer ou non).\n",
        "\n"
      ],
      "metadata": {
        "id": "JhLRuQfmauld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \"\"\"\n",
        "        It is a simple convolutional network\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define the input shape based on your data\n",
        "input_shape = (512, 512, 1)  # Adjust according to your data\n",
        "model = build_model(input_shape)\n",
        "\n",
        "# Callback for early stopping\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "N5peIWgVOQIc",
        "execution": {
          "iopub.status.busy": "2024-03-10T12:41:04.108268Z",
          "iopub.execute_input": "2024-03-10T12:41:04.109381Z",
          "iopub.status.idle": "2024-03-10T12:41:04.305572Z",
          "shell.execute_reply.started": "2024-03-10T12:41:04.109336Z",
          "shell.execute_reply": "2024-03-10T12:41:04.304575Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n"
      ],
      "metadata": {
        "id": "duCDF9Bhaule"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, batch_size=16,\n",
        "                    validation_data=(X_val, y_val), callbacks = early_stopping)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:41:08.40227Z",
          "iopub.execute_input": "2024-03-10T12:41:08.402671Z",
          "iopub.status.idle": "2024-03-10T12:41:33.005774Z",
          "shell.execute_reply.started": "2024-03-10T12:41:08.402636Z",
          "shell.execute_reply": "2024-03-10T12:41:33.00467Z"
        },
        "trusted": true,
        "id": "oojaZLczaule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation du modèle\n"
      ],
      "metadata": {
        "id": "XautQBsKaule"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:41:55.020872Z",
          "iopub.execute_input": "2024-03-10T12:41:55.021998Z",
          "iopub.status.idle": "2024-03-10T12:41:56.467445Z",
          "shell.execute_reply.started": "2024-03-10T12:41:55.021955Z",
          "shell.execute_reply": "2024-03-10T12:41:56.466341Z"
        },
        "trusted": true,
        "id": "wqjkSKz3aulo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "# plt.ylim([0.95,1])\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig(\"resnet_accuracy98.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:41:59.229219Z",
          "iopub.execute_input": "2024-03-10T12:41:59.230316Z",
          "iopub.status.idle": "2024-03-10T12:41:59.463424Z",
          "shell.execute_reply.started": "2024-03-10T12:41:59.23026Z",
          "shell.execute_reply": "2024-03-10T12:41:59.46248Z"
        },
        "trusted": true,
        "id": "TRvjOzqiaulo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "# plt.ylim([0.05,0.3])\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.savefig(\"resnet_loss.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:42:07.089359Z",
          "iopub.execute_input": "2024-03-10T12:42:07.090659Z",
          "iopub.status.idle": "2024-03-10T12:42:07.37812Z",
          "shell.execute_reply.started": "2024-03-10T12:42:07.090623Z",
          "shell.execute_reply": "2024-03-10T12:42:07.377108Z"
        },
        "trusted": true,
        "id": "I-1GUTB4aulo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilisation du modèle pour la prédiction\n"
      ],
      "metadata": {
        "id": "Piugv8Yaaulo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:42:15.028981Z",
          "iopub.execute_input": "2024-03-10T12:42:15.030098Z",
          "iopub.status.idle": "2024-03-10T12:42:15.44258Z",
          "shell.execute_reply.started": "2024-03-10T12:42:15.030055Z",
          "shell.execute_reply": "2024-03-10T12:42:15.441418Z"
        },
        "trusted": true,
        "id": "nG1wHcYNaulw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "plot_model(model, to_file='luna.png', show_shapes=True,show_layer_names=True)\n",
        "Image(filename='luna.png')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-10T12:42:20.797665Z",
          "iopub.execute_input": "2024-03-10T12:42:20.798563Z",
          "iopub.status.idle": "2024-03-10T12:42:21.22989Z",
          "shell.execute_reply.started": "2024-03-10T12:42:20.798523Z",
          "shell.execute_reply": "2024-03-10T12:42:21.228644Z"
        },
        "trusted": true,
        "id": "eNd4zvF3aulw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYvZaQOzaulx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}